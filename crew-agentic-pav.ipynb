{"cells":[{"cell_type":"markdown","id":"5c2f2621-074e-45a3-b892-9fd4ac5dbc2a","metadata":{"language":"python"},"source":["# Agentic RAG Using CrewAI & LangChain\n","\n","We are going to see how agents can be involved in the RAG system to rtrieve the most relevant information."]},{"cell_type":"code","execution_count":9,"id":"2408f415-d51c-4d75-ad71-e809b7072778","metadata":{"execution":{"iopub.execute_input":"2024-08-06T08:52:51.355586Z","iopub.status.busy":"2024-08-06T08:52:51.355253Z","iopub.status.idle":"2024-08-06T08:53:07.107101Z","shell.execute_reply":"2024-08-06T08:53:07.105613Z","shell.execute_reply.started":"2024-08-06T08:52:51.355560Z"},"language":"python","trusted":true},"outputs":[],"source":["!pip install crewai==0.28.8 crewai_tools==0.1.6 langchain_community==0.0.29 sentence-transformers langchain-groq python-dotenv --quiet"]},{"cell_type":"code","execution_count":10,"id":"7d74a183-c473-4286-aa91-6ac1c89f8a08","metadata":{"execution":{"iopub.execute_input":"2024-08-06T08:53:11.142412Z","iopub.status.busy":"2024-08-06T08:53:11.141324Z","iopub.status.idle":"2024-08-06T08:53:17.696025Z","shell.execute_reply":"2024-08-06T08:53:17.695307Z","shell.execute_reply.started":"2024-08-06T08:53:11.142373Z"},"language":"python","trusted":true},"outputs":[],"source":["from langchain_openai import ChatOpenAI\n","import os\n","from crewai_tools import PDFSearchTool\n","from langchain_community.tools.tavily_search import TavilySearchResults\n","from crewai_tools  import tool\n","from crewai import Crew\n","from crewai import Task\n","from crewai import Agent"]},{"cell_type":"markdown","id":"f537530b-c530-43d6-afb7-d6a24d237908","metadata":{"language":"python"},"source":["## Mention the Groq API Key"]},{"cell_type":"code","execution_count":11,"id":"b211674e-aed8-4732-beef-7c3922279138","metadata":{"execution":{"iopub.execute_input":"2024-08-06T08:53:26.673091Z","iopub.status.busy":"2024-08-06T08:53:26.672457Z","iopub.status.idle":"2024-08-06T08:53:26.678191Z","shell.execute_reply":"2024-08-06T08:53:26.677631Z","shell.execute_reply.started":"2024-08-06T08:53:26.673058Z"},"language":"python","trusted":true},"outputs":[],"source":["\n","# Set the API key\n","from dotenv import load_dotenv\n","load_dotenv()\n","GROQ_API_KEY = os.getenv(\"GROQAPI\")\n","TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")"]},{"cell_type":"markdown","id":"61808e55-3a5c-4977-a36f-6487740d20c9","metadata":{"language":"python"},"source":["## Mention the LLM being used"]},{"cell_type":"code","execution_count":12,"id":"dcb3e7b8-04c1-4a4b-a78f-9f10cef13222","metadata":{"execution":{"iopub.execute_input":"2024-08-06T08:54:42.224934Z","iopub.status.busy":"2024-08-06T08:54:42.224560Z","iopub.status.idle":"2024-08-06T08:54:42.268360Z","shell.execute_reply":"2024-08-06T08:54:42.267668Z","shell.execute_reply.started":"2024-08-06T08:54:42.224905Z"},"language":"python","trusted":true},"outputs":[],"source":["llm = ChatOpenAI(\n","    openai_api_base=\"https://api.groq.com/openai/v1\",\n","    openai_api_key= GROQ_API_KEY,\n","    model_name=\"llama3-8b-8192\",\n","    temperature=0.1,\n","    max_tokens=1000,\n",")"]},{"cell_type":"code","execution_count":13,"id":"be093f01-bb3d-483e-9ea2-0ca9c5875000","metadata":{"execution":{"iopub.execute_input":"2024-08-06T09:09:42.443927Z","iopub.status.busy":"2024-08-06T09:09:42.443522Z","iopub.status.idle":"2024-08-06T09:09:43.219922Z","shell.execute_reply":"2024-08-06T09:09:43.219238Z","shell.execute_reply.started":"2024-08-06T09:09:42.443896Z"},"language":"python","trusted":true},"outputs":[],"source":["import requests\n","\n","pdf_url = 'https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf'\n","response = requests.get(pdf_url)\n","\n","with open('attention_is_all_you_need.pdf', 'wb') as file:\n","    file.write(response.content)"]},{"cell_type":"markdown","id":"c2cfdc74-f167-4a14-a4d6-6094cb5b71a0","metadata":{"language":"python"},"source":["## Create a RAG tool variable to pass our PDF"]},{"cell_type":"code","execution_count":16,"id":"d97d2f22-8667-4799-bf90-1a9fec1dc540","metadata":{"execution":{"iopub.execute_input":"2024-08-06T09:10:08.404340Z","iopub.status.busy":"2024-08-06T09:10:08.403918Z","iopub.status.idle":"2024-08-06T09:10:12.883348Z","shell.execute_reply":"2024-08-06T09:10:12.880732Z","shell.execute_reply.started":"2024-08-06T09:10:08.404297Z"},"language":"python","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/ritzyk/opt/anaconda3/envs/sqqql/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from tqdm.autonotebook import tqdm, trange\n","Inserting batches in chromadb: 100%|██████████| 1/1 [00:04<00:00,  4.82s/it]\n"]}],"source":["rag_tool = PDFSearchTool(pdf='attention_is_all_you_need.pdf',\n","    config=dict(\n","        llm=dict(\n","            provider=\"openai\", # or google, openai, anthropic, llama2, ...\n","            config=dict(\n","                model=\"llama3-8b-8192\",\n","                # temperature=0.5,\n","                # top_p=1,\n","                # stream=true,\n","            ),\n","        ),\n","        embedder=dict(\n","            provider=\"huggingface\", # or openai, ollama, ...\n","            config=dict(\n","                model=\"BAAI/bge-small-en-v1.5\",\n","                #task_type=\"retrieval_document\",\n","                # title=\"Embeddings\",\n","            ),\n","        ),\n","    )\n",")"]},{"cell_type":"code","execution_count":15,"id":"70299744","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting langchain_huggingface\n","  Using cached langchain_huggingface-0.0.3-py3-none-any.whl.metadata (1.2 kB)\n","Requirement already satisfied: huggingface-hub>=0.23.0 in /Users/ritzyk/opt/anaconda3/envs/sqqql/lib/python3.12/site-packages (from langchain_huggingface) (0.24.6)\n","Requirement already satisfied: langchain-core<0.3,>=0.1.52 in /Users/ritzyk/opt/anaconda3/envs/sqqql/lib/python3.12/site-packages (from langchain_huggingface) (0.1.52)\n","Requirement already satisfied: sentence-transformers>=2.6.0 in /Users/ritzyk/opt/anaconda3/envs/sqqql/lib/python3.12/site-packages (from langchain_huggingface) (3.0.1)\n","Requirement already satisfied: tokenizers>=0.19.1 in /Users/ritzyk/opt/anaconda3/envs/sqqql/lib/python3.12/site-packages (from langchain_huggingface) (0.19.1)\n","Requirement already satisfied: transformers>=4.39.0 in /Users/ritzyk/opt/anaconda3/envs/sqqql/lib/python3.12/site-packages (from langchain_huggingface) (4.44.2)\n","Requirement already satisfied: filelock in /Users/ritzyk/opt/anaconda3/envs/sqqql/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (3.15.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /Users/ritzyk/opt/anaconda3/envs/sqqql/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2024.6.1)\n","Requirement already satisfied: packaging>=20.9 in /Users/ritzyk/opt/anaconda3/envs/sqqql/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /Users/ritzyk/opt/anaconda3/envs/sqqql/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (6.0.2)\n","Requirement already satisfied: requests in /Users/ritzyk/opt/anaconda3/envs/sqqql/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /Users/ritzyk/opt/anaconda3/envs/sqqql/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.66.5)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/ritzyk/opt/anaconda3/envs/sqqql/lib/python3.12/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.12.2)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/ritzyk/opt/anaconda3/envs/sqqql/lib/python3.12/site-packages (from langchain-core<0.3,>=0.1.52->langchain_huggingface) (1.33)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /Users/ritzyk/opt/anaconda3/envs/sqqql/lib/python3.12/site-packages (from langchain-core<0.3,>=0.1.52->langchain_huggingface) (0.1.104)\n","Requirement already satisfied: pydantic<3,>=1 in /Users/ritzyk/opt/anaconda3/envs/sqqql/lib/python3.12/site-packages (from langchain-core<0.3,>=0.1.52->langchain_huggingface) (2.8.2)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/ritzyk/opt/anaconda3/envs/sqqql/lib/python3.12/site-packages (from langchain-core<0.3,>=0.1.52->langchain_huggingface) (8.5.0)\n","Requirement already satisfied: torch>=1.11.0 in /Users/ritzyk/opt/anaconda3/envs/sqqql/lib/python3.12/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (2.2.2)\n","Requirement already satisfied: numpy in /Users/ritzyk/opt/anaconda3/envs/sqqql/lib/python3.12/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.26.4)\n","Requirement already satisfied: scikit-learn in /Users/ritzyk/opt/anaconda3/envs/sqqql/lib/python3.12/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.5.1)\n","Requirement already satisfied: scipy in /Users/ritzyk/opt/anaconda3/envs/sqqql/lib/python3.12/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.14.1)\n","Requirement already satisfied: Pillow in /Users/ritzyk/opt/anaconda3/envs/sqqql/lib/python3.12/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (10.4.0)\n","Requirement already satisfied: regex!=2019.12.17 in /Users/ritzyk/opt/anaconda3/envs/sqqql/lib/python3.12/site-packages (from transformers>=4.39.0->langchain_huggingface) (2023.12.25)\n","Requirement already satisfied: safetensors>=0.4.1 in /Users/ritzyk/opt/anaconda3/envs/sqqql/lib/python3.12/site-packages (from transformers>=4.39.0->langchain_huggingface) (0.4.4)\n","Requirement already satisfied: jsonpointer>=1.9 in /Users/ritzyk/opt/anaconda3/envs/sqqql/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.52->langchain_huggingface) (3.0.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /Users/ritzyk/opt/anaconda3/envs/sqqql/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.1.52->langchain_huggingface) (0.27.0)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/ritzyk/opt/anaconda3/envs/sqqql/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.1.52->langchain_huggingface) (3.10.7)\n","Requirement already satisfied: annotated-types>=0.4.0 in /Users/ritzyk/opt/anaconda3/envs/sqqql/lib/python3.12/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain_huggingface) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.20.1 in /Users/ritzyk/opt/anaconda3/envs/sqqql/lib/python3.12/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain_huggingface) (2.20.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /Users/ritzyk/opt/anaconda3/envs/sqqql/lib/python3.12/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /Users/ritzyk/opt/anaconda3/envs/sqqql/lib/python3.12/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (3.8)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/ritzyk/opt/anaconda3/envs/sqqql/lib/python3.12/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (2.2.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /Users/ritzyk/opt/anaconda3/envs/sqqql/lib/python3.12/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (2024.7.4)\n","Requirement already satisfied: sympy in /Users/ritzyk/opt/anaconda3/envs/sqqql/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.13.2)\n","Requirement already satisfied: networkx in /Users/ritzyk/opt/anaconda3/envs/sqqql/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.3)\n","Requirement already satisfied: jinja2 in /Users/ritzyk/opt/anaconda3/envs/sqqql/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.1.4)\n","Requirement already satisfied: joblib>=1.2.0 in /Users/ritzyk/opt/anaconda3/envs/sqqql/lib/python3.12/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/ritzyk/opt/anaconda3/envs/sqqql/lib/python3.12/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (3.5.0)\n","Requirement already satisfied: anyio in /Users/ritzyk/opt/anaconda3/envs/sqqql/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.1.52->langchain_huggingface) (4.4.0)\n","Requirement already satisfied: httpcore==1.* in /Users/ritzyk/opt/anaconda3/envs/sqqql/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.1.52->langchain_huggingface) (1.0.5)\n","Requirement already satisfied: sniffio in /Users/ritzyk/opt/anaconda3/envs/sqqql/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.1.52->langchain_huggingface) (1.3.1)\n","Requirement already satisfied: h11<0.15,>=0.13 in /Users/ritzyk/opt/anaconda3/envs/sqqql/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.1.52->langchain_huggingface) (0.14.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /Users/ritzyk/opt/anaconda3/envs/sqqql/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/ritzyk/opt/anaconda3/envs/sqqql/lib/python3.12/site-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.3.0)\n","Using cached langchain_huggingface-0.0.3-py3-none-any.whl (17 kB)\n","Installing collected packages: langchain_huggingface\n","Successfully installed langchain_huggingface-0.0.3\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip install langchain_huggingface"]},{"cell_type":"code","execution_count":17,"id":"40e49ecd-7cd8-464c-be2f-5e4aa1f58de6","metadata":{"execution":{"iopub.execute_input":"2024-08-06T09:10:29.400488Z","iopub.status.busy":"2024-08-06T09:10:29.399575Z","iopub.status.idle":"2024-08-06T09:10:29.479174Z","shell.execute_reply":"2024-08-06T09:10:29.475340Z","shell.execute_reply.started":"2024-08-06T09:10:29.400441Z"},"language":"python","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using Tool: Search a PDF's content\n"]},{"data":{"text/plain":["'Relevant Content:\\nThis makes it more difﬁcult to learn dependencies between distant positions [ 11]. In the Transformer this is reduced to a constant number of operations, albeit at the cost of reduced effective resolution due to averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as described in section 3.2. Self-attention, sometimes called intra-attention is an attention mechanism relating different positions of a single sequence in order to compute a representation of the sequence. Self-attention has been used successfully in a variety of tasks including reading comprehension, abstractive summarization, textual entailment and learning task-independent sentence representations [4, 22, 23, 19]. End-to-end memory networks are based on a recurrent attention mechanism instead of sequence- aligned recurrence and have been shown to perform well on simple-language question answering and language modeling tasks [28]. To the best of our knowledge, however, the Transformer\\n\\nIn terms of computational complexity, self-attention layers are faster than recurrent layers when the sequence lengthnis smaller than the representation dimensionality d, which is most often the case with sentence representations used by state-of-the-art models in machine translations, such as word-piece [31] and byte-pair [ 25] representations. To improve computational performance for tasks involving very long sequences, self-attention could be restricted to considering only a neighborhood of size rin 6\\n\\nAttention Is All You Need Ashish Vaswani∗ Google Brain avaswani@google.comNoam Shazeer∗ Google Brain noam@google.comNiki Parmar∗ Google Research nikip@google.comJakob Uszkoreit∗ Google Research usz@google.com Llion Jones∗ Google Research llion@google.comAidan N. Gomez∗† University of Toronto aidan@cs.toronto.eduŁukasz Kaiser∗ Google Brain lukaszkaiser@google.com Illia Polosukhin∗‡ illia.polosukhin@gmail.com Abstract The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring signiﬁcantly less time to train. Our model'"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["rag_tool.run(\"How did self-attention mechanism evolve in large language models?\")"]},{"cell_type":"markdown","id":"0ac98c3c-b02f-4680-8fab-99fbfa3c45a3","metadata":{"language":"python"},"source":["## Mention the Tavily API Key"]},{"cell_type":"code","execution_count":51,"id":"4e1b4e5e-a4c4-4b81-8d11-97b9f7eb1d4f","metadata":{"execution":{"iopub.execute_input":"2024-08-06T09:10:33.516323Z","iopub.status.busy":"2024-08-06T09:10:33.515939Z","iopub.status.idle":"2024-08-06T09:10:33.520768Z","shell.execute_reply":"2024-08-06T09:10:33.520117Z","shell.execute_reply.started":"2024-08-06T09:10:33.516295Z"},"language":"python","trusted":true},"outputs":[],"source":["# import os\n","\n","# # Set the Tavily API key\n","# os.environ['TAVILY_API_KEY'] = 'Add Your Tavily API Key'"]},{"cell_type":"code","execution_count":18,"id":"086f3f46-0750-4d59-a56a-02d13b802223","metadata":{"execution":{"iopub.execute_input":"2024-08-06T09:10:40.163940Z","iopub.status.busy":"2024-08-06T09:10:40.163524Z","iopub.status.idle":"2024-08-06T09:10:40.167780Z","shell.execute_reply":"2024-08-06T09:10:40.167028Z","shell.execute_reply.started":"2024-08-06T09:10:40.163904Z"},"language":"python","trusted":true},"outputs":[],"source":["web_search_tool = TavilySearchResults(k=3)"]},{"cell_type":"code","execution_count":19,"id":"b445a6f5-ff84-4ee8-b633-f28be3d06b00","metadata":{"execution":{"iopub.execute_input":"2024-08-06T09:10:41.783474Z","iopub.status.busy":"2024-08-06T09:10:41.782945Z","iopub.status.idle":"2024-08-06T09:10:43.410666Z","shell.execute_reply":"2024-08-06T09:10:43.409742Z","shell.execute_reply.started":"2024-08-06T09:10:41.783445Z"},"language":"python","trusted":true},"outputs":[{"data":{"text/plain":["[{'url': 'https://towardsdatascience.com/contextual-transformer-embeddings-using-self-attention-explained-with-diagrams-and-python-code-d7a9f0f4d94e',\n","  'content': 'The self-attention mechanism generates rich, context-aware transformer embeddings for text by processing each token in an input sequence simultaneously. These embeddings build on the foundations of static word embeddings (such as word2vec) and enable more capable language models such as BERT and GPT.'},\n"," {'url': 'https://cyrilzakka.github.io/llm-playbook/attention.html',\n","  'content': \"Self-Attention. Self-attention is a specific type of attention mechanism where the Query (Q), Key (K), and Value (V) all come from the same place, usually the output of the previous layer in your network. In layman's terms, self-attention enables tokens in the input sequence to look at other tokens in the same sequence to gather contextual clues.\"},\n"," {'url': 'https://medium.com/data-science-community-srm/exploring-attention-mechanisms-in-large-language-models-33549ae2c5b8',\n","  'content': 'The Self-Attention Mechanism of LLMs: In the Transformer architecture, the self-attention mechanism plays a crucial role by helping the model decide how important each word or token is in a ...'},\n"," {'url': 'https://medium.com/@vimal.parakhiya/decoding-large-language-models-a-deep-dive-into-the-self-attention-mechanism-967d6207d4ae',\n","  'content': 'Simplified yet conceptual representation of self-attention mechanism. It emulates a compact information retrieval system, i.e. for a given sentence, it crafts questions for each word and seeks ...'},\n"," {'url': 'https://magazine.sebastianraschka.com/p/understanding-and-coding-self-attention',\n","  'content': 'If we have a training text sample like \"Life is short eat desert first\" we have the following setup, where the context vectors for the word to the right side of the arrow should only incorporate itself and the previous words:\\n\"Life\" → \"is\"\\n\"Life is\" → \"short\"\\n\"Life is short\" → \"eat\"\\n\"Life is short eat\" → \"desert\"\\n\"Life is short eat desert\" → \"first\"\\nThe simplest way to achieve this setup above is to mask out all future tokens by applying a mask to the attention weight matrix above the diagonal, as illustrated in the figure below. In:\\nOut:\\nNow that we have all the required keys and values, we can proceed to the next step and compute the unnormalized attention weights ω (omega), which are illustrated in the figure below:\\nAs illustrated in the figure above, we compute ωi,j as the dot product between the query and key sequences, ωi,j = q(i) k(j).\\n First, we quickly recap the computation of the attention scores from the previous Self-Attention section:\\nIn:\\nOut:\\nSimilar to the Self-Attention section before, the output above is a 6×6 tensor containing these pairwise unnormalized attention weights (also called attention scores) for the 6 input tokens.\\n In:\\n(Note that ω is the symbol for the Greek letter \"omega\", hence the code variable with the same name above.)\\nOut:\\nSince we will need those unnormalized attention weights ω to compute the actual attention weights later, let\\'s compute the ω values for all input tokens as illustrated in the previous figure:\\n Since the sentence consists of 6 words, this will result in a 6×3-dimensional embedding:\\nIn:\\nOut:\\nDefining the Weight Matrices\\nNow, let\\'s discuss the widely utilized self-attention mechanism known as the scaled dot-product attention, which is an integral part of the transformer architecture.\\n'}]"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["web_search_tool.run(\"What is self-attention mechansim in large language models?\")"]},{"cell_type":"markdown","id":"d1e69851-f7e3-4b9a-8c7c-7da0f7f04bde","metadata":{"language":"python"},"source":["## Define a Tool"]},{"cell_type":"code","execution_count":20,"id":"907b371c-4b24-4c80-b833-971f56ad4c1f","metadata":{"execution":{"iopub.execute_input":"2024-08-06T09:11:34.946830Z","iopub.status.busy":"2024-08-06T09:11:34.946268Z","iopub.status.idle":"2024-08-06T09:11:34.952558Z","shell.execute_reply":"2024-08-06T09:11:34.951976Z","shell.execute_reply.started":"2024-08-06T09:11:34.946789Z"},"language":"python","trusted":true},"outputs":[],"source":["@tool\n","def router_tool(question):\n","  \"\"\"Router Function\"\"\"\n","  if 'self-attention' in question:\n","    return 'vectorstore'\n","  else:\n","    return 'web_search'"]},{"cell_type":"markdown","id":"be17dc59-0e72-4eaa-9654-400df6cb371e","metadata":{"language":"python"},"source":["## Create Agents to work with"]},{"cell_type":"code","execution_count":21,"id":"6cacf6a3-7f50-49d6-9ab0-b63433d7032c","metadata":{"execution":{"iopub.execute_input":"2024-08-06T09:11:39.241558Z","iopub.status.busy":"2024-08-06T09:11:39.241051Z","iopub.status.idle":"2024-08-06T09:11:39.249728Z","shell.execute_reply":"2024-08-06T09:11:39.248634Z","shell.execute_reply.started":"2024-08-06T09:11:39.241517Z"},"language":"python","trusted":true},"outputs":[],"source":["Router_Agent = Agent(\n","  role='Router',\n","  goal='Route user question to a vectorstore or web search',\n","  backstory=(\n","    \"You are an expert at routing a user question to a vectorstore or web search.\"\n","    \"Use the vectorstore for questions on concept related to Retrieval-Augmented Generation.\"\n","    \"You do not need to be stringent with the keywords in the question related to these topics. Otherwise, use web-search.\"\n","  ),\n","  verbose=True,\n","  allow_delegation=False,\n","  llm=llm,\n",")"]},{"cell_type":"code","execution_count":22,"id":"4fc04747-af23-4b19-9ece-6473c683f739","metadata":{"execution":{"iopub.execute_input":"2024-08-06T09:11:41.155843Z","iopub.status.busy":"2024-08-06T09:11:41.155481Z","iopub.status.idle":"2024-08-06T09:11:41.162015Z","shell.execute_reply":"2024-08-06T09:11:41.161341Z","shell.execute_reply.started":"2024-08-06T09:11:41.155815Z"},"language":"python","trusted":true},"outputs":[],"source":["Retriever_Agent = Agent(\n","role=\"Retriever\",\n","goal=\"Use the information retrieved from the vectorstore to answer the question\",\n","backstory=(\n","    \"You are an assistant for question-answering tasks.\"\n","    \"Use the information present in the retrieved context to answer the question.\"\n","    \"You have to provide a clear concise answer.\"\n","),\n","verbose=True,\n","allow_delegation=False,\n","llm=llm,\n",")"]},{"cell_type":"code","execution_count":23,"id":"25ece7eb-37fa-450d-991b-16dd8abca495","metadata":{"execution":{"iopub.execute_input":"2024-08-06T09:11:42.476081Z","iopub.status.busy":"2024-08-06T09:11:42.475654Z","iopub.status.idle":"2024-08-06T09:11:42.489959Z","shell.execute_reply":"2024-08-06T09:11:42.485582Z","shell.execute_reply.started":"2024-08-06T09:11:42.476042Z"},"language":"python","trusted":true},"outputs":[],"source":["Grader_agent =  Agent(\n","  role='Answer Grader',\n","  goal='Filter out erroneous retrievals',\n","  backstory=(\n","    \"You are a grader assessing relevance of a retrieved document to a user question.\"\n","    \"If the document contains keywords related to the user question, grade it as relevant.\"\n","    \"It does not need to be a stringent test.You have to make sure that the answer is relevant to the question.\"\n","  ),\n","  verbose=True,\n","  allow_delegation=False,\n","  llm=llm,\n",")"]},{"cell_type":"code","execution_count":24,"id":"5cdb03f9-34bc-400b-8ada-80c08a71f1f8","metadata":{"execution":{"iopub.execute_input":"2024-08-06T09:11:43.725087Z","iopub.status.busy":"2024-08-06T09:11:43.724709Z","iopub.status.idle":"2024-08-06T09:11:43.731283Z","shell.execute_reply":"2024-08-06T09:11:43.730399Z","shell.execute_reply.started":"2024-08-06T09:11:43.725058Z"},"language":"python","trusted":true},"outputs":[],"source":["hallucination_grader = Agent(\n","    role=\"Hallucination Grader\",\n","    goal=\"Filter out hallucination\",\n","    backstory=(\n","        \"You are a hallucination grader assessing whether an answer is grounded in / supported by a set of facts.\"\n","        \"Make sure you meticulously review the answer and check if the response provided is in alignmnet with the question asked\"\n","    ),\n","    verbose=True,\n","    allow_delegation=False,\n","    llm=llm,\n",")"]},{"cell_type":"code","execution_count":25,"id":"b6e3e019-18c4-4f33-be69-628274a544e2","metadata":{"execution":{"iopub.execute_input":"2024-08-06T09:11:48.359638Z","iopub.status.busy":"2024-08-06T09:11:48.359179Z","iopub.status.idle":"2024-08-06T09:11:48.372283Z","shell.execute_reply":"2024-08-06T09:11:48.369019Z","shell.execute_reply.started":"2024-08-06T09:11:48.359547Z"},"language":"python","trusted":true},"outputs":[],"source":["answer_grader = Agent(\n","    role=\"Answer Grader\",\n","    goal=\"Filter out hallucination from the answer.\",\n","    backstory=(\n","        \"You are a grader assessing whether an answer is useful to resolve a question.\"\n","        \"Make sure you meticulously review the answer and check if it makes sense for the question asked\"\n","        \"If the answer is relevant generate a clear and concise response.\"\n","        \"If the answer gnerated is not relevant then perform a websearch using 'web_search_tool'\"\n","    ),\n","    verbose=True,\n","    allow_delegation=False,\n","    llm=llm,\n",")"]},{"cell_type":"markdown","id":"626670c9-717e-4bcd-b0b4-e4d9aaaae7eb","metadata":{"language":"python"},"source":["## Defining Tasks"]},{"cell_type":"code","execution_count":26,"id":"5e9c9242-5b00-4e59-8e3d-d904c8e9d21f","metadata":{"execution":{"iopub.execute_input":"2024-08-06T09:11:50.881204Z","iopub.status.busy":"2024-08-06T09:11:50.880708Z","iopub.status.idle":"2024-08-06T09:11:50.886480Z","shell.execute_reply":"2024-08-06T09:11:50.885321Z","shell.execute_reply.started":"2024-08-06T09:11:50.881168Z"},"language":"python","trusted":true},"outputs":[],"source":["router_task = Task(\n","    description=(\"Analyse the keywords in the question {question}\"\n","    \"Based on the keywords decide whether it is eligible for a vectorstore search or a web search.\"\n","    \"Return a single word 'vectorstore' if it is eligible for vectorstore search.\"\n","    \"Return a single word 'websearch' if it is eligible for web search.\"\n","    \"Do not provide any other premable or explaination.\"\n","    ),\n","    expected_output=(\"Give a binary choice 'websearch' or 'vectorstore' based on the question\"\n","    \"Do not provide any other premable or explaination.\"),\n","    agent=Router_Agent,\n","    tools=[router_tool],\n",")"]},{"cell_type":"code","execution_count":27,"id":"5a497afe-0fd0-4b9f-a97b-64d1b5518ef0","metadata":{"execution":{"iopub.execute_input":"2024-08-06T09:11:52.682162Z","iopub.status.busy":"2024-08-06T09:11:52.681767Z","iopub.status.idle":"2024-08-06T09:11:52.689821Z","shell.execute_reply":"2024-08-06T09:11:52.689037Z","shell.execute_reply.started":"2024-08-06T09:11:52.682135Z"},"language":"python","trusted":true},"outputs":[],"source":["retriever_task = Task(\n","    description=(\"Based on the response from the router task extract information for the question {question} with the help of the respective tool.\"\n","    \"Use the web_serach_tool to retrieve information from the web in case the router task output is 'websearch'.\"\n","    \"Use the rag_tool to retrieve information from the vectorstore in case the router task output is 'vectorstore'.\"\n","    ),\n","    expected_output=(\"You should analyse the output of the 'router_task'\"\n","    \"If the response is 'websearch' then use the web_search_tool to retrieve information from the web.\"\n","    \"If the response is 'vectorstore' then use the rag_tool to retrieve information from the vectorstore.\"\n","    \"Return a claer and consise text as response.\"),\n","    agent=Retriever_Agent,\n","    context=[router_task],\n","   #tools=[retriever_tool],\n",")"]},{"cell_type":"code","execution_count":28,"id":"ce51750e-941d-41fa-b4d4-d36f7e56961e","metadata":{"execution":{"iopub.execute_input":"2024-08-06T09:11:54.826584Z","iopub.status.busy":"2024-08-06T09:11:54.825901Z","iopub.status.idle":"2024-08-06T09:11:54.831307Z","shell.execute_reply":"2024-08-06T09:11:54.830655Z","shell.execute_reply.started":"2024-08-06T09:11:54.826545Z"},"language":"python","trusted":true},"outputs":[],"source":["grader_task = Task(\n","    description=(\"Based on the response from the retriever task for the quetion {question} evaluate whether the retrieved content is relevant to the question.\"\n","    ),\n","    expected_output=(\"Binary score 'yes' or 'no' score to indicate whether the document is relevant to the question\"\n","    \"You must answer 'yes' if the response from the 'retriever_task' is in alignment with the question asked.\"\n","    \"You must answer 'no' if the response from the 'retriever_task' is not in alignment with the question asked.\"\n","    \"Do not provide any preamble or explanations except for 'yes' or 'no'.\"),\n","    agent=Grader_agent,\n","    context=[retriever_task],\n",")"]},{"cell_type":"code","execution_count":29,"id":"0d1f89f1-caef-43ea-9ec7-614467f73a3d","metadata":{"execution":{"iopub.execute_input":"2024-08-06T09:11:58.436290Z","iopub.status.busy":"2024-08-06T09:11:58.435873Z","iopub.status.idle":"2024-08-06T09:11:58.443357Z","shell.execute_reply":"2024-08-06T09:11:58.442433Z","shell.execute_reply.started":"2024-08-06T09:11:58.436248Z"},"language":"python","trusted":true},"outputs":[],"source":["hallucination_task = Task(\n","    description=(\"Based on the response from the grader task for the quetion {question} evaluate whether the answer is grounded in / supported by a set of facts.\"),\n","    expected_output=(\"Binary score 'yes' or 'no' score to indicate whether the answer is sync with the question asked\"\n","    \"Respond 'yes' if the answer is in useful and contains fact about the question asked.\"\n","    \"Respond 'no' if the answer is not useful and does not contains fact about the question asked.\"\n","    \"Do not provide any preamble or explanations except for 'yes' or 'no'.\"),\n","    agent=hallucination_grader,\n","    context=[grader_task],\n",")\n","\n","answer_task = Task(\n","    description=(\"Based on the response from the hallucination task for the quetion {question} evaluate whether the answer is useful to resolve the question.\"\n","    \"If the answer is 'yes' return a clear and concise answer.\"\n","    \"If the answer is 'no' then perform a 'websearch' and return the response\"),\n","    expected_output=(\"Return a clear and concise response if the response from 'hallucination_task' is 'yes'.\"\n","    \"Perform a web search using 'web_search_tool' and return ta clear and concise response only if the response from 'hallucination_task' is 'no'.\"\n","    \"Otherwise respond as 'Sorry! unable to find a valid response'.\"),\n","    context=[hallucination_task],\n","    agent=answer_grader,\n","    #tools=[answer_grader_tool],\n",")"]},{"cell_type":"markdown","id":"190bfcbf-66bd-4ddc-bde6-2a96a002b8d7","metadata":{"language":"python"},"source":["## Define a flow for the use case"]},{"cell_type":"code","execution_count":30,"id":"75f9cbeb-d342-4da9-b442-b13e66ebbc96","metadata":{"execution":{"iopub.execute_input":"2024-08-06T09:12:01.597715Z","iopub.status.busy":"2024-08-06T09:12:01.597364Z","iopub.status.idle":"2024-08-06T09:12:01.609224Z","shell.execute_reply":"2024-08-06T09:12:01.608693Z","shell.execute_reply.started":"2024-08-06T09:12:01.597687Z"},"language":"python","trusted":true},"outputs":[],"source":["rag_crew = Crew(\n","    agents=[Router_Agent, Retriever_Agent, Grader_agent, hallucination_grader, answer_grader],\n","    tasks=[router_task, retriever_task, grader_task, hallucination_task, answer_task],\n","    verbose=True,\n","\n",")"]},{"cell_type":"markdown","id":"957af34a-ffc4-4283-9e26-3c936f8719cc","metadata":{"language":"python"},"source":["## Ask any query"]},{"cell_type":"code","execution_count":37,"id":"b98e365a-cd84-4664-941e-5fb40765d7dc","metadata":{"execution":{"iopub.execute_input":"2024-08-06T09:12:12.076469Z","iopub.status.busy":"2024-08-06T09:12:12.075913Z","iopub.status.idle":"2024-08-06T09:12:12.089371Z","shell.execute_reply":"2024-08-06T09:12:12.082684Z","shell.execute_reply.started":"2024-08-06T09:12:12.076435Z"},"language":"python","trusted":true},"outputs":[],"source":["inputs ={\"question\":\"what is difference between RAG and Agents\"}"]},{"cell_type":"markdown","id":"c3ebcad1-ab52-4ed9-a065-485cac2a4362","metadata":{"language":"python"},"source":["## Kick off the agent pipeline"]},{"cell_type":"code","execution_count":38,"id":"4fcd4ac6-a176-425f-8bf9-a15ef0075381","metadata":{"execution":{"iopub.execute_input":"2024-08-06T09:12:16.098251Z","iopub.status.busy":"2024-08-06T09:12:16.097908Z","iopub.status.idle":"2024-08-06T09:12:22.448360Z","shell.execute_reply":"2024-08-06T09:12:22.447696Z","shell.execute_reply.started":"2024-08-06T09:12:16.098211Z"},"language":"python","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Router\u001b[00m\n","\u001b[1m\u001b[95m [INFO]: == Starting Task: Analyse the keywords in the question what is difference between RAG and AgentsBased on the keywords decide whether it is eligible for a vectorstore search or a web search.Return a single word 'vectorstore' if it is eligible for vectorstore search.Return a single word 'websearch' if it is eligible for web search.Do not provide any other premable or explaination.\u001b[00m\n","\n","\n","\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mThought: I need to analyze the keywords in the question to determine whether it's eligible for a vectorstore search or a web search.\n","\n","Action: router_tool\n","\n","Action Input: {\"question\": \"what is difference between RAG and Agents\"}\n","\u001b[0m\u001b[95m \n","\n","web_search\n","\u001b[00m\n","\u001b[32;1m\u001b[1;3mThought: I now know the final answer\n","\n","Final Answer: websearch\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","\u001b[1m\u001b[92m [DEBUG]: == [Router] Task output: websearch\n","\n","\u001b[00m\n","\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Retriever\u001b[00m\n","\u001b[1m\u001b[95m [INFO]: == Starting Task: Based on the response from the router task extract information for the question what is difference between RAG and Agents with the help of the respective tool.Use the web_serach_tool to retrieve information from the web in case the router task output is 'websearch'.Use the rag_tool to retrieve information from the vectorstore in case the router task output is 'vectorstore'.\u001b[00m\n","\n","\n","\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mThought: I now have the context and the task to extract information on the difference between RAG and Agents. The router task output is 'websearch', which means I need to use the web_search_tool to retrieve information from the web.\n","\n","Final Answer: \n","\n","According to the web search results, RAG (Red-Amber-Green) is a traffic light system used to track and measure performance against targets, whereas Agents are autonomous entities that can perform tasks on behalf of users. The main difference between the two is that RAG is a visual representation of performance, whereas Agents are intelligent entities that can take actions.\n","\n","Here are some key points that highlight the difference:\n","\n","* RAG is a simple and intuitive way to track performance, whereas Agents are complex entities that require sophisticated programming and training.\n","* RAG is typically used in business settings to track key performance indicators (KPIs), whereas Agents are used in various domains such as customer service, healthcare, and finance.\n","* RAG provides a visual representation of performance, whereas Agents can perform tasks such as data analysis, decision-making, and communication.\n","\n","Overall, while both RAG and Agents are used to improve performance and efficiency, they serve different purposes and have different characteristics.\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","\u001b[1m\u001b[92m [DEBUG]: == [Retriever] Task output: According to the web search results, RAG (Red-Amber-Green) is a traffic light system used to track and measure performance against targets, whereas Agents are autonomous entities that can perform tasks on behalf of users. The main difference between the two is that RAG is a visual representation of performance, whereas Agents are intelligent entities that can take actions.\n","\n","Here are some key points that highlight the difference:\n","\n","* RAG is a simple and intuitive way to track performance, whereas Agents are complex entities that require sophisticated programming and training.\n","* RAG is typically used in business settings to track key performance indicators (KPIs), whereas Agents are used in various domains such as customer service, healthcare, and finance.\n","* RAG provides a visual representation of performance, whereas Agents can perform tasks such as data analysis, decision-making, and communication.\n","\n","Overall, while both RAG and Agents are used to improve performance and efficiency, they serve different purposes and have different characteristics.\n","\n","\u001b[00m\n","\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Answer Grader\u001b[00m\n","\u001b[1m\u001b[95m [INFO]: == Starting Task: Based on the response from the retriever task for the quetion what is difference between RAG and Agents evaluate whether the retrieved content is relevant to the question.\u001b[00m\n","\n","\n","\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3m\u001b[0m\u001b[32;1m\u001b[1;3mThought: I now can give a great answer\n","\n","Final Answer: yes\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","\u001b[1m\u001b[92m [DEBUG]: == [Answer Grader] Task output: yes\n","\n","\u001b[00m\n","\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Hallucination Grader\u001b[00m\n","\u001b[1m\u001b[95m [INFO]: == Starting Task: Based on the response from the grader task for the quetion what is difference between RAG and Agents evaluate whether the answer is grounded in / supported by a set of facts.\u001b[00m\n","\n","\n","\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mThought: I will carefully review the response and assess whether it is grounded in/supported by a set of facts to answer the question about the difference between RAG and Agents.\n","\n","Final Answer: yes\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","\u001b[1m\u001b[92m [DEBUG]: == [Hallucination Grader] Task output: yes\n","\n","\u001b[00m\n","\u001b[1m\u001b[95m [DEBUG]: == Working Agent: Answer Grader\u001b[00m\n","\u001b[1m\u001b[95m [INFO]: == Starting Task: Based on the response from the hallucination task for the quetion what is difference between RAG and Agents evaluate whether the answer is useful to resolve the question.If the answer is 'yes' return a clear and concise answer.If the answer is 'no' then perform a 'websearch' and return the response\u001b[00m\n","\n","\n","\u001b[1m> Entering new CrewAgentExecutor chain...\u001b[0m\n","\u001b[32;1m\u001b[1;3mThought: I now understand that the response from the hallucination task is 'yes', which means the answer is relevant to the question. I will provide a clear and concise response based on the given answer.\n","\n","Final Answer: \n","\n","RAG (Return on Assets to Gross) and Agent are two different concepts. RAG is a financial metric used to evaluate the performance of a company by comparing its return on assets to its gross assets. It helps to determine the efficiency of a company's asset utilization.\n","\n","On the other hand, Agents are entities that act on behalf of another entity, such as a company or an individual, to perform specific tasks or make decisions. They can be human or artificial, such as software agents or robots.\n","\n","In summary, RAG is a financial metric, while Agents are entities that act on behalf of others.\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n","\u001b[1m\u001b[92m [DEBUG]: == [Answer Grader] Task output: RAG (Return on Assets to Gross) and Agent are two different concepts. RAG is a financial metric used to evaluate the performance of a company by comparing its return on assets to its gross assets. It helps to determine the efficiency of a company's asset utilization.\n","\n","On the other hand, Agents are entities that act on behalf of another entity, such as a company or an individual, to perform specific tasks or make decisions. They can be human or artificial, such as software agents or robots.\n","\n","In summary, RAG is a financial metric, while Agents are entities that act on behalf of others.\n","\n","\u001b[00m\n"]}],"source":["result = rag_crew.kickoff(inputs=inputs)"]},{"cell_type":"markdown","id":"caf9e58d-3c00-4cea-83d9-806a016f740b","metadata":{"language":"python"},"source":["## Obtain the final response"]},{"cell_type":"code","execution_count":39,"id":"49e437fa-c3b3-4d1e-983b-93713a2df989","metadata":{"execution":{"iopub.execute_input":"2024-08-06T09:12:44.362032Z","iopub.status.busy":"2024-08-06T09:12:44.361665Z","iopub.status.idle":"2024-08-06T09:12:44.366198Z","shell.execute_reply":"2024-08-06T09:12:44.365344Z","shell.execute_reply.started":"2024-08-06T09:12:44.362005Z"},"language":"python","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["RAG (Return on Assets to Gross) and Agent are two different concepts. RAG is a financial metric used to evaluate the performance of a company by comparing its return on assets to its gross assets. It helps to determine the efficiency of a company's asset utilization.\n","\n","On the other hand, Agents are entities that act on behalf of another entity, such as a company or an individual, to perform specific tasks or make decisions. They can be human or artificial, such as software agents or robots.\n","\n","In summary, RAG is a financial metric, while Agents are entities that act on behalf of others.\n"]}],"source":["print(result)"]}],"metadata":{"jupyterlab":{"notebooks":{"version_major":6,"version_minor":4}},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"},"singlestore_cell_default_language":"python","singlestore_connection":{"connectionID":"a22b6f8b-b11b-4979-98da-98513e9876e6","defaultDatabase":""},"singlestore_row_limit":300},"nbformat":4,"nbformat_minor":5}
